# -*- coding: utf-8 -*-
"""LifeExpectancy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oZ0ULCcIdT1cZNDPRs-dbH4je4IBFIrE
"""

from google.colab import drive
drive.mount('/content/gdrive')

cd /content/gdrive/My Drive/dataset/

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import matplotlib.pyplot as plt

dataset=pd.read_csv("/content/gdrive/My Drive/dataset/Life Expectancy Data.csv")
X=dataset.iloc[:,:-1].values
Y=dataset.iloc[:,1].values

dataset.describe()

dataset.head()

dataset.info()

dataset["Status"].value_counts()

"""### **Splitting Dataset into training and testing**"""

from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(dataset, dataset['Status']):
  strat_train_set= dataset.loc[train_index]
  strat_test_set= dataset.loc[test_index]

strat_train_set.info()

strat_test_set.info()

strat_test_set["Status"].value_counts()

strat_train_set["Status"].value_counts()

print(486/102)
print(1940/410)
#equal ratio me train test data split hua with respect to "Status"

#sare analysis training dataset pe hoga
strat_train_set.hist(bins=50,figsize=(20,15) )

"""### **Looking for correlations**"""

corr_matrix= strat_train_set.corr()
corr_matrix["Life expectancy "].sort_values(ascending=False)

from pandas.plotting import scatter_matrix
attributes=["Life expectancy ","Schooling","Income composition of resources"," BMI ","Adult Mortality"," HIV/AIDS"]
scatter_matrix(strat_train_set[attributes],figsize =(16,10))

strat_train_set.plot(kind="scatter", x="Schooling", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))
strat_train_set.plot(kind="scatter", x="Income composition of resources", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))
strat_train_set.plot(kind="scatter", x=" BMI ", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))

strat_train_set.plot(kind="scatter", x="Adult Mortality", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))
strat_train_set.plot(kind="scatter", x=" HIV/AIDS", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))
strat_train_set.plot(kind="scatter", x=" thinness  1-19 years", y ="Life expectancy ", alpha =0.8 ,figsize=(6,4))



"""**splitting features and labels**"""

#features_train=strat_train_set.drop("Life expectancy ",axis=1)
#labels_train = strat_train_set["Life expectancy "].copy()

"""## **FIlling missing attributes**"""

#labels_train.info()



"""**Creating Pipleline**"""

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
my_pipeline =Pipeline([
    ('imputer', SimpleImputer(strategy ="median" )),
    # ......... add as many as you want in pipeline
    ])



strat_train_set.replace({"Developed":1, "Developing":0},inplace=True)
strat_train_set["Status"].value_counts()

train_set_tr=my_pipeline.fit_transform(strat_train_set.iloc[:, 1:  ])

#labels_train_tr=my_pipeline.fit_transform([labels_train])
#cannot impute label data through pipeline
#we had to drop country as it is a non numeric value
strat_train_set.head()

#here we can see al values have been filled
#train_set_tr was a numpy array so we converted into pandas dataframe first
df = pd.DataFrame(train_set_tr)
labels_train=df.iloc[0:,2]
features_train=df.drop(df.columns[[2]], axis=1)

#2 columns removed ,life expectancy and country
features_train.values



"""## **Selecting a desired model for the Data Set**"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
modelR = LinearRegression()
modelD=DecisionTreeRegressor()
modelF=RandomForestRegressor()
modelR.fit(features_train, labels_train)
modelD.fit(features_train, labels_train)
modelF.fit(features_train, labels_train)

features_train

"""### Evaluating the Model"""

from sklearn.metrics import mean_squared_error
Life_Predict = modelF.predict(features_train)
mse=mean_squared_error(labels_train,Life_Predict)
rmse= np.sqrt(mse)

rmse
#in decision tree rmse is 0 due to overfitting

strat_train_set.values[2]

feats=np.array([[2.00800000e+03, 1.00000000e+00, 8.80000000e+01, 0.00000000e+00,
       1.07000000e+01, 1.07611821e+04, 9.20000000e+01, 1.40000000e+01,
       5.63000000e+01, 0.00000000e+00, 8.80000000e+01, 1.18000000e+00,
       8.80000000e+01, 1.00000000e-01, 6.43226664e+04, 5.49362100e+06,
       1.10000000e+00, 9.00000000e-01, 9.06000000e-01, 1.68000000e+01]])
modelR.predict(feats)

feats=np.array([[2008, 1 , 88.0, 0, 10.7, 10761.18209, 50, 14,
       56.3, 0, 88.0, 1.18, 88.0, 0.1, 64322.6664, 5493621.0, 1.1, 0.9,
       0.906, 16.8]])
modelR.predict(feats)

"""## Using Better evaluation technique -Cross Validation"""

from sklearn.model_selection import cross_val_score
#decision tree
DT_scores = cross_val_score(modelD,features_train ,labels_train , scoring="neg_mean_squared_error", cv=10)
LR_scores=cross_val_score(modelR,features_train ,labels_train , scoring="neg_mean_squared_error", cv=10)
RF_scores=cross_val_score(modelF,features_train ,labels_train , scoring="neg_mean_squared_error", cv=10)

import numpy as np
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
results=cross_val_score(modelD,features_train, labels_train, cv=KFold(10))
results.mean()

DT_scores

DT_rmse=np.sqrt(-DT_scores)
print("For Decision Tree")
DT_rmse.mean()

LR_rmse=np.sqrt(-LR_scores)
print("For Linear Regression")
LR_rmse.mean()

RF_rmse=np.sqrt(-RF_scores)
print("For Random Forest")
RF_rmse.mean()

"""## Testing the Model on Test Data"""

strat_test_set.replace({"Developed":1, "Developing":0},inplace=True)
#train_set_tr=my_pipeline.fit_transform(strat_train_set.iloc[:, 1:  ])
strat_test_set["Status"].value_counts()
X_test_prepared=my_pipeline.transform(strat_test_set.iloc[:, 1:  ])

d = pd.DataFrame(X_test_prepared)
labels_test=d.iloc[0:,2]
features_test=d.drop(df.columns[[2]], axis=1)

"""# **ese hi**"""



ft=df.iloc[:,-1:]
modelR.fit(ft, labels_train)
from sklearn.metrics import mean_squared_error
Life_Predict = modelR.predict(ft)
LR_scores=cross_val_score(modelR,ft ,labels_train , scoring="neg_mean_squared_error", cv=10)
LR_scores
LR_rmse=np.sqrt(-LR_scores)
print("For Linear Regression")
LR_rmse.mean()

"""cross validation is used for data training, not in testing

from sklearn.model_selection import cross_val_score
#decision tree
DT_sc = cross_val_score(modelD,features_test ,labels_test , scoring="neg_mean_squared_error", cv=10)
LR_sc=cross_val_score(modelR,features_test ,labels_test , scoring="neg_mean_squared_error", cv=10)
RF_sc=cross_val_score(modelF,features_test ,labels_test , scoring="neg_mean_squared_error", cv=10)"
"""

prediction=modelR.predict(features_test)
final_mse = mean_squared_error(labels_test, prediction)
final_rmse = np.sqrt(final_mse)
final_rmse

prediction=modelD.predict(features_test)
final_mse = mean_squared_error(labels_test, prediction)
final_rmse = np.sqrt(final_mse)
final_rmse

prediction=modelF.predict(features_test)
final_mse = mean_squared_error(labels_test, prediction)
final_rmse = np.sqrt(final_mse)
final_rmse

feats=np.array([[2.00800000e+03, 1.00000000e+00, 8.80000000e+01, 0.00000000e+00,
       1.07000000e+01, 1.07611821e+04, 9.20000000e+01, 1.40000000e+01,
       5.63000000e+01, 0.00000000e+00, 8.80000000e+01, 1.18000000e+00,
       8.80000000e+01, 1.00000000e-01, 6.43226664e+04, 5.49362100e+06,
       1.10000000e+00, 9.00000000e-01, 9.06000000e-01, 1.68000000e+01]])
print("real value is 78")
print(f"Prediction by Linear Regression {modelR.predict(feats)} ")
print(f"Prediction by Decision Tree {modelD.predict(feats)} ")
print(f"Prediction by Random Forest {modelF.predict(feats)} ")

#features_test.values[0]
feats=np.array([[2.01500000e+03, 0.00000000e+00, 2.75000000e+02, 4.00000000e+00,
       3.79000000e+00, 0.00000000e+00, 8.70000000e+01, 1.53000000e+02,
       2.63000000e+01, 6.00000000e+00, 8.70000000e+01, 5.78500000e+00,
       8.70000000e+01, 3.20000000e+00, 5.96871719e+02, 1.77526000e+05,
       7.10000000e+00, 7.00000000e+00, 4.21000000e-01, 9.20000000e+00]])
print("real value is 58.9")
print(f"Prediction by Linear Regression {modelR.predict(feats)} ")
print(f"Prediction by Decision Tree {modelD.predict(feats)} ")
print(f"Prediction by Random Forest {modelF.predict(feats)} ")



strat_test_set